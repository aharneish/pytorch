{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WaEYOOulYb6c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torchvision import datasets,transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import make_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RKdT90eyYb6f"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork,self).__init__()\n",
        "        self.flatten=nn.Flatten()\n",
        "        self.linear_relu_stack=nn.Sequential(\n",
        "            nn.Linear(28*28,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,11)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4vuXEh4Yb6f",
        "outputId": "a0994338-59bd-41da-b82e-8137e910b737"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=11, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=NeuralNetwork()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNBCbMe3Yb6g",
        "outputId": "b1b9746a-0086-4d87-d685-f8688e37de88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0202, -0.0044, -0.0224,  ..., -0.0247,  0.0350, -0.0033],\n",
            "        [ 0.0119, -0.0281, -0.0343,  ...,  0.0147, -0.0222, -0.0031],\n",
            "        [ 0.0149,  0.0084, -0.0012,  ..., -0.0083, -0.0326, -0.0184],\n",
            "        ...,\n",
            "        [ 0.0274,  0.0337, -0.0179,  ...,  0.0060,  0.0142,  0.0122],\n",
            "        [ 0.0218,  0.0282,  0.0286,  ..., -0.0154,  0.0317,  0.0185],\n",
            "        [ 0.0274, -0.0300, -0.0012,  ..., -0.0054, -0.0342,  0.0331]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 1.9796e-03,  4.1293e-03,  1.7657e-02, -2.9076e-02,  6.4790e-03,\n",
            "        -6.5577e-03,  2.8824e-02, -4.6274e-03,  3.0778e-02,  1.5061e-03,\n",
            "         7.6805e-03,  3.5374e-02, -3.2288e-02, -2.9598e-02, -2.1085e-02,\n",
            "         2.6498e-02,  2.3608e-02, -3.3666e-02, -7.3708e-04,  3.2514e-02,\n",
            "        -1.9400e-02, -1.1159e-02,  1.1949e-04, -3.4641e-02,  2.2658e-02,\n",
            "         2.9286e-02,  1.5624e-02, -2.3486e-03,  3.0307e-02, -2.4252e-02,\n",
            "        -1.4238e-03, -3.0327e-02, -2.1190e-02, -3.0394e-03, -4.8626e-03,\n",
            "         3.1306e-02, -1.3234e-02,  3.4007e-02,  3.5559e-02,  2.5285e-02,\n",
            "         8.5465e-05,  9.5217e-03,  1.5847e-02,  1.3282e-02, -1.5309e-02,\n",
            "         1.3477e-02,  8.2698e-03, -2.0412e-02, -2.0235e-02,  2.2429e-02,\n",
            "         2.0655e-02,  3.4518e-02, -1.4132e-03, -3.2601e-02, -1.1187e-02,\n",
            "        -1.5776e-02,  2.0961e-02,  5.3789e-03,  3.3898e-02, -3.0719e-02,\n",
            "         1.7602e-02, -9.1465e-03,  1.3221e-02,  1.9650e-02,  2.1353e-02,\n",
            "         6.1948e-03, -1.6835e-02, -3.4573e-02, -4.5610e-03,  1.6160e-02,\n",
            "        -2.2200e-02, -3.3282e-02, -3.4867e-02, -9.0775e-03, -2.9196e-02,\n",
            "        -3.1556e-02,  2.4310e-02,  1.3789e-02, -2.3492e-02,  2.6058e-02,\n",
            "        -1.8082e-02, -1.6814e-02, -3.5883e-03, -6.5927e-03,  2.9404e-02,\n",
            "        -2.3149e-02, -2.2106e-02, -2.6795e-03, -2.1694e-02, -3.3273e-02,\n",
            "         3.5167e-02, -9.1587e-05,  2.5787e-02, -2.0397e-03, -1.5654e-02,\n",
            "        -3.1930e-02, -1.1156e-02,  2.6692e-02, -8.2513e-03, -6.4340e-03,\n",
            "         2.4282e-03, -2.2861e-02,  6.1137e-03, -2.9619e-02, -2.4739e-02,\n",
            "         1.7674e-02, -2.1038e-02,  4.6809e-03, -9.0772e-03,  3.3402e-02,\n",
            "         2.7185e-02,  2.3686e-02, -1.7777e-02, -1.2655e-02, -3.2333e-02,\n",
            "         1.9152e-02, -2.4325e-02,  2.1968e-02,  2.2210e-02,  2.8494e-02,\n",
            "         1.9837e-02,  1.1816e-02, -2.0607e-02,  3.2194e-02,  3.8118e-03,\n",
            "         1.0827e-02, -1.3482e-02, -1.3362e-02,  1.1751e-02,  2.3566e-02,\n",
            "         3.5188e-03, -1.3787e-02, -5.3004e-03,  1.4034e-02,  1.7586e-02,\n",
            "         1.4249e-02, -1.4517e-02, -2.8804e-02,  1.7376e-02,  6.7474e-03,\n",
            "        -5.4722e-03, -1.6022e-02,  2.9400e-02,  3.9971e-03, -2.4477e-02,\n",
            "        -2.3948e-02, -9.2660e-03, -7.1311e-03,  2.6594e-02,  2.2769e-02,\n",
            "        -2.9871e-02, -3.0344e-02,  2.1079e-04,  2.7961e-03, -7.7235e-03,\n",
            "         1.4017e-02, -7.0996e-03, -3.0718e-02,  1.0862e-02,  1.5403e-02,\n",
            "         2.1286e-02, -1.8247e-02, -2.4966e-02, -4.7370e-03,  8.5842e-03,\n",
            "         2.6494e-02, -1.3909e-02,  3.2760e-02,  3.1066e-02,  1.3330e-02,\n",
            "        -2.5431e-03,  2.4314e-03, -1.5698e-02, -7.9691e-03,  3.1825e-02,\n",
            "        -8.1379e-03,  2.5609e-02,  3.1992e-02, -5.7545e-03, -6.3729e-03,\n",
            "        -1.0832e-02, -1.9912e-02,  2.5056e-02,  3.1403e-02, -1.9901e-02,\n",
            "        -2.2133e-02,  1.3672e-02, -1.1224e-02,  3.2518e-02, -1.1673e-02,\n",
            "        -2.3885e-02, -3.3417e-02,  3.1010e-02, -2.8522e-02, -1.8745e-02,\n",
            "        -1.9185e-02,  2.9108e-02,  3.3975e-02, -1.7806e-02, -6.5165e-03,\n",
            "         9.1591e-03,  3.2128e-02, -1.2149e-02,  2.1774e-02, -1.2853e-02,\n",
            "        -3.0258e-02,  4.0314e-03,  1.8029e-03,  2.3285e-02, -2.7291e-02,\n",
            "         1.4132e-02,  2.5664e-02,  1.3405e-02,  8.2147e-03, -9.3415e-03,\n",
            "        -2.4474e-02, -2.0636e-02, -2.4953e-02, -9.2058e-03,  2.2928e-02,\n",
            "        -2.2883e-02,  2.7714e-02,  3.4469e-02, -2.4772e-02,  1.8069e-02,\n",
            "        -2.2044e-02,  1.3062e-02, -5.0735e-03,  2.0654e-02, -2.8976e-02,\n",
            "         3.3252e-02, -9.7130e-04, -1.6439e-02,  1.3953e-02,  1.6162e-02,\n",
            "        -3.3228e-02,  4.5397e-03, -1.8249e-02,  3.0822e-02, -2.8051e-02,\n",
            "         8.3723e-03,  1.9858e-02,  3.4731e-02, -3.7837e-03,  3.1377e-02,\n",
            "         1.4765e-04,  9.8328e-03, -2.1071e-02, -1.9616e-02,  3.4685e-04,\n",
            "        -1.2008e-02,  2.6911e-03, -2.8478e-02,  2.1527e-02, -6.8638e-03,\n",
            "        -5.1530e-03,  9.8495e-03, -1.7073e-03,  1.2564e-02,  3.1712e-02,\n",
            "         3.3527e-02,  3.5825e-03, -2.7548e-02, -1.4537e-02,  2.4099e-02,\n",
            "        -2.5417e-03,  2.5626e-02,  7.2225e-03, -2.0946e-02, -2.7071e-03,\n",
            "         3.0118e-03,  2.7989e-03, -2.5382e-02,  3.3260e-02, -6.1833e-03,\n",
            "         2.6560e-02,  2.8055e-03,  2.4965e-02, -6.2363e-04, -1.1527e-02,\n",
            "         2.4944e-02, -2.2836e-02,  2.9314e-02, -3.4033e-02,  2.3600e-02,\n",
            "        -2.1328e-02,  1.7529e-02, -3.4660e-02,  1.7886e-02, -2.3290e-02,\n",
            "        -2.7677e-03,  3.1311e-02,  2.4061e-03, -3.5455e-02,  1.8469e-02,\n",
            "        -3.2466e-02,  2.4988e-02, -2.6014e-02, -9.3044e-03,  1.0477e-02,\n",
            "         4.0789e-03, -1.6931e-02,  3.2213e-02, -7.7024e-03,  1.3344e-02,\n",
            "         1.6405e-02, -8.2472e-03,  8.4668e-03,  1.0064e-02,  1.2663e-02,\n",
            "         1.2437e-02,  1.7978e-02,  3.2273e-02,  2.0552e-02, -2.9347e-02,\n",
            "         8.9750e-03, -2.5701e-02,  1.9512e-02, -1.6286e-02, -3.1949e-02,\n",
            "         1.4551e-02,  2.1172e-02, -2.8988e-02, -5.2265e-03,  9.9674e-03,\n",
            "         2.1575e-02,  2.7221e-02, -3.2247e-03,  5.9570e-03,  1.3682e-02,\n",
            "        -2.0768e-02,  2.2660e-02,  5.0297e-03,  1.1783e-02, -2.8157e-02,\n",
            "         2.0446e-03,  1.8501e-03, -1.3276e-02,  2.5715e-03,  1.8148e-02,\n",
            "         6.5963e-03,  1.8348e-02,  7.8507e-03, -5.7333e-03, -2.6628e-02,\n",
            "        -1.2509e-02, -1.0623e-02,  1.5684e-02, -2.9155e-02,  2.4754e-02,\n",
            "         1.0217e-02, -2.0427e-02, -3.4300e-02,  1.3405e-02,  1.1792e-02,\n",
            "         3.1564e-02,  3.1976e-02,  5.1059e-04,  2.4761e-02,  1.8271e-02,\n",
            "         1.4019e-02,  2.5366e-02,  6.1628e-03,  8.7193e-03,  1.1810e-02,\n",
            "         2.7150e-02, -2.1894e-02, -2.2275e-02,  1.5129e-02, -4.3626e-03,\n",
            "         2.7578e-02, -1.9079e-02, -3.1775e-02,  3.3934e-03, -1.6727e-02,\n",
            "        -3.2393e-02, -2.9895e-02,  2.1637e-02,  2.1476e-02,  2.4797e-02,\n",
            "        -3.2733e-04, -1.0721e-03,  8.2885e-03, -3.4413e-02, -3.4710e-02,\n",
            "         2.5571e-02, -2.1859e-02,  1.6138e-02,  5.2115e-03, -2.9943e-02,\n",
            "        -1.2305e-02,  2.4059e-02, -1.0395e-02,  1.0876e-02, -3.1806e-02,\n",
            "         1.5497e-02, -5.4163e-03, -8.6396e-03, -4.7149e-03, -2.2584e-03,\n",
            "        -3.0499e-02, -2.6011e-02,  1.3195e-02, -1.7474e-02, -1.4539e-02,\n",
            "         2.5296e-02, -1.3926e-02,  5.8924e-03, -1.1570e-03, -1.7776e-02,\n",
            "         8.2976e-03,  2.8332e-02, -9.5546e-03,  2.6694e-02,  2.1658e-02,\n",
            "         1.2790e-02,  2.0819e-02,  1.6548e-02,  2.6106e-02,  6.2474e-03,\n",
            "         2.5239e-02, -1.7437e-02, -3.2809e-02, -1.2939e-02,  2.4469e-03,\n",
            "        -8.5860e-04,  2.0554e-02, -1.5864e-02,  2.2133e-02,  3.1160e-02,\n",
            "         8.8355e-03,  1.9450e-02, -2.0479e-02, -1.1363e-02, -2.5327e-02,\n",
            "        -5.0177e-03,  8.8448e-03, -1.1150e-02,  3.0513e-02, -1.6994e-03,\n",
            "        -2.7045e-02,  1.3360e-02,  1.5908e-02, -2.6940e-02, -1.8715e-02,\n",
            "        -7.5521e-03,  3.2755e-03, -3.0028e-03,  3.0906e-02,  3.2310e-03,\n",
            "        -1.4525e-03,  1.6455e-02,  1.2846e-02, -4.5296e-03, -3.6942e-03,\n",
            "         1.4627e-02,  3.2342e-02,  1.6232e-02,  9.7578e-04,  1.1121e-02,\n",
            "        -3.4747e-02,  1.0083e-03,  2.6620e-02, -2.6232e-02, -6.9284e-04,\n",
            "        -3.5279e-02,  2.5050e-04, -8.5924e-04,  2.7176e-03,  3.1314e-02,\n",
            "        -7.5450e-03,  1.2471e-02,  3.2917e-02, -5.4816e-03,  1.3858e-02,\n",
            "        -2.6546e-02, -1.8474e-03,  2.7013e-02,  3.4629e-02, -1.0730e-02,\n",
            "         4.9403e-03, -3.3663e-02, -2.9142e-02,  2.0877e-02,  1.3552e-02,\n",
            "        -3.4327e-02,  3.5676e-03, -3.0928e-02, -2.4969e-02,  8.3905e-03,\n",
            "         3.5132e-02, -2.0101e-02,  2.8215e-02,  1.5380e-02, -1.1933e-02,\n",
            "         2.6124e-02,  1.9319e-02,  1.8260e-02, -1.0047e-02, -3.3087e-02,\n",
            "        -2.3472e-02, -8.5426e-03,  1.2933e-02, -3.8184e-03, -3.1808e-02,\n",
            "         3.0776e-02,  9.1876e-03,  9.0994e-03, -3.1009e-02,  7.2123e-04,\n",
            "         2.1078e-02,  7.8326e-03], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0310, -0.0199, -0.0043,  ...,  0.0087,  0.0137,  0.0014],\n",
            "        [-0.0376, -0.0023, -0.0186,  ..., -0.0022, -0.0230, -0.0227],\n",
            "        [ 0.0361, -0.0421,  0.0300,  ..., -0.0081, -0.0014,  0.0099],\n",
            "        ...,\n",
            "        [ 0.0282,  0.0314, -0.0096,  ...,  0.0278, -0.0392,  0.0433],\n",
            "        [ 0.0095,  0.0154, -0.0170,  ..., -0.0416, -0.0181,  0.0254],\n",
            "        [ 0.0213, -0.0135,  0.0434,  ..., -0.0056,  0.0057, -0.0348]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 1.9198e-02, -1.9476e-02,  1.7707e-02, -3.5227e-02,  4.2996e-02,\n",
            "         7.0657e-04, -1.3778e-02,  4.0214e-02,  3.3571e-02, -2.6064e-02,\n",
            "         1.2150e-02, -2.4232e-02,  7.5898e-03, -2.8226e-03, -3.1999e-02,\n",
            "         2.7380e-02,  2.9000e-02, -3.6458e-02,  2.2490e-02,  3.2099e-02,\n",
            "        -3.9350e-02,  2.1795e-02, -3.7819e-02, -3.2654e-02,  1.7431e-02,\n",
            "         4.1070e-02, -3.4039e-02,  2.4919e-02,  1.5018e-02, -1.7954e-02,\n",
            "        -1.0932e-02,  3.7741e-02, -4.5128e-03, -4.2281e-02,  4.6549e-03,\n",
            "        -4.4037e-02,  1.1948e-02, -1.5216e-02,  4.0800e-02,  1.8998e-02,\n",
            "         5.0250e-03,  1.1607e-02, -3.6863e-02,  2.8855e-02,  3.4965e-02,\n",
            "        -4.8541e-03,  2.2261e-02,  1.2754e-02,  3.6831e-03,  2.5816e-02,\n",
            "        -4.0239e-02, -4.1470e-02, -1.4343e-02, -2.6224e-02,  5.6586e-03,\n",
            "        -7.4944e-04,  7.6813e-03,  2.8847e-02, -1.7449e-02, -2.1569e-02,\n",
            "        -3.7893e-02, -3.3026e-02,  1.4375e-02, -1.6753e-02,  4.3078e-02,\n",
            "        -5.5096e-04,  4.9265e-03, -1.6338e-02, -4.2975e-02, -3.7248e-02,\n",
            "        -8.5860e-03, -8.3579e-03,  1.9070e-02,  3.3455e-03, -2.6488e-02,\n",
            "         3.7509e-02, -2.6159e-02,  3.5404e-02, -6.3576e-03, -3.4155e-02,\n",
            "         2.4090e-02,  9.4107e-03,  2.9165e-02,  2.5338e-02,  2.9257e-02,\n",
            "        -3.5689e-02, -3.1000e-02,  7.2349e-03,  4.1471e-02,  1.4570e-02,\n",
            "        -3.1100e-02,  2.7049e-02, -2.0885e-02, -3.5407e-02,  3.9971e-02,\n",
            "        -3.1646e-02, -2.3474e-02, -3.9172e-02, -1.5903e-02,  6.3709e-04,\n",
            "         9.7072e-03,  3.2951e-02, -2.3809e-02, -9.1622e-03, -1.8957e-02,\n",
            "        -2.2525e-02, -1.0731e-03,  2.4964e-02,  1.3321e-03,  2.7553e-03,\n",
            "         1.4032e-02,  4.1222e-02, -3.8548e-02, -3.6182e-02,  2.2944e-02,\n",
            "         3.3541e-02, -2.3441e-02, -2.9574e-02,  4.2581e-02,  2.9184e-03,\n",
            "        -1.6186e-02, -2.2442e-02,  1.9760e-02,  9.7218e-03,  6.8486e-03,\n",
            "        -1.2636e-02,  1.6338e-02,  2.0002e-02, -3.0194e-02,  7.1280e-03,\n",
            "         1.5273e-02, -4.3292e-02,  3.1361e-02, -2.2889e-02, -1.6525e-02,\n",
            "        -3.1603e-02, -2.3367e-02,  3.6422e-02, -2.8721e-02,  4.9687e-03,\n",
            "         3.1209e-02, -5.8698e-03,  2.9662e-02,  2.7881e-02,  2.3015e-02,\n",
            "        -2.0759e-03,  1.5708e-02,  3.1083e-02,  1.8622e-02,  2.6134e-02,\n",
            "        -1.4073e-02, -3.2714e-02, -1.9989e-02,  6.1519e-03,  2.1328e-02,\n",
            "        -1.9207e-02,  3.4442e-02, -2.0744e-02,  1.0171e-02, -2.9921e-02,\n",
            "        -2.2781e-02, -2.7495e-02,  8.2540e-03, -3.5120e-02, -1.7889e-02,\n",
            "        -3.7747e-02,  7.7221e-03,  4.0648e-02, -2.4277e-02,  3.3670e-02,\n",
            "        -9.5225e-03, -9.5122e-03,  3.5915e-02, -3.4093e-03, -1.2591e-02,\n",
            "        -3.7680e-02,  2.8724e-03, -1.9558e-02,  4.4008e-02,  4.4110e-02,\n",
            "         1.4846e-02, -1.7389e-02, -3.2667e-02,  5.1246e-03, -2.3187e-02,\n",
            "         2.5706e-02,  9.3623e-03, -1.8591e-02,  2.7435e-02,  1.1004e-02,\n",
            "         3.1663e-02, -3.8388e-02, -2.5843e-02,  3.0829e-02, -8.5707e-03,\n",
            "         9.3182e-03,  1.4815e-02,  4.7800e-03,  9.2778e-03,  4.2544e-02,\n",
            "        -1.9007e-02,  3.6000e-02, -1.2767e-02, -1.8047e-02,  3.6434e-02,\n",
            "         8.8349e-03,  3.1631e-02, -2.3725e-02,  1.9061e-03,  1.2185e-02,\n",
            "         4.0387e-02,  3.9164e-02, -1.9140e-02, -3.8013e-02, -4.2226e-02,\n",
            "        -2.0519e-03, -1.4509e-02, -2.7737e-02,  3.9787e-02, -3.1733e-03,\n",
            "        -4.1997e-02,  3.3655e-02, -3.0084e-02,  1.5020e-02,  1.7915e-02,\n",
            "         1.8380e-02,  1.6819e-02,  4.0380e-02,  2.5875e-02, -2.0069e-02,\n",
            "         6.5293e-03,  3.1908e-02,  1.4970e-02, -1.2877e-02, -1.4480e-04,\n",
            "        -3.8076e-03,  3.0788e-02, -3.0312e-02,  8.8819e-03, -1.9513e-02,\n",
            "         3.0329e-02, -2.6716e-02,  3.9371e-02,  2.6318e-03,  2.6570e-02,\n",
            "        -2.5123e-02,  9.3512e-03, -1.9559e-02,  3.2576e-02, -1.9945e-02,\n",
            "         4.3347e-03, -2.7743e-04, -3.4487e-02, -3.6243e-02, -8.0686e-03,\n",
            "         2.4765e-02, -7.4211e-03,  9.8247e-03,  4.0928e-02, -3.1892e-02,\n",
            "         2.2417e-02,  3.0688e-02,  1.1848e-02,  2.8156e-02,  2.6139e-02,\n",
            "         8.6308e-03,  2.7135e-02,  4.4091e-02, -3.1351e-02,  9.2458e-03,\n",
            "         3.4125e-02,  3.2469e-02, -1.3740e-02,  2.0676e-03, -1.9139e-02,\n",
            "         5.7397e-03,  4.0107e-02, -2.9498e-02,  2.8322e-02,  2.8613e-02,\n",
            "        -1.8854e-02,  3.7291e-02,  1.6648e-02, -2.7410e-02, -2.2370e-02,\n",
            "        -1.1660e-02,  2.5779e-02, -2.9937e-02, -3.4240e-02,  3.4549e-02,\n",
            "         3.1730e-02, -1.0335e-02, -3.3544e-02,  3.5671e-02,  2.2171e-03,\n",
            "         2.8903e-02, -6.0762e-03,  1.4877e-02, -1.1352e-02,  3.4026e-02,\n",
            "        -2.5001e-02,  3.3346e-02, -1.6796e-02,  2.9386e-02,  3.3929e-02,\n",
            "        -3.1490e-02, -2.6562e-02, -2.3093e-02, -3.8321e-03,  5.6260e-03,\n",
            "        -2.9662e-02, -4.0161e-02,  3.2115e-02, -6.4767e-03,  3.7137e-02,\n",
            "        -6.7578e-03,  2.2872e-02, -2.1276e-02,  1.6034e-02, -4.0772e-02,\n",
            "        -4.0744e-02,  2.2390e-02,  8.1090e-03,  3.3223e-02,  2.6826e-02,\n",
            "        -1.0649e-02, -2.5100e-03,  4.2379e-02, -1.1406e-02, -7.7725e-03,\n",
            "         4.2730e-02, -2.6935e-02, -3.1835e-02,  8.3673e-03,  1.5693e-02,\n",
            "         1.8750e-02,  1.9727e-02,  3.0455e-03,  3.3472e-02, -3.3470e-02,\n",
            "        -4.3775e-04, -2.2475e-02,  2.0957e-02,  2.8615e-04, -1.5943e-02,\n",
            "        -4.3942e-02, -2.3764e-02,  4.3688e-02,  2.5760e-02,  4.0981e-02,\n",
            "        -3.6228e-02, -5.7840e-03,  5.1884e-03,  1.4164e-02,  3.5136e-02,\n",
            "         4.2362e-02,  2.3980e-02, -4.2831e-02,  2.8920e-02, -1.2658e-02,\n",
            "        -2.4448e-02, -1.2455e-02, -1.3859e-02, -2.6986e-02,  6.5285e-03,\n",
            "        -9.9445e-03,  3.6390e-03,  3.2925e-02,  9.2819e-03, -4.3693e-02,\n",
            "         9.7421e-03, -3.8559e-03, -4.7388e-03,  1.4609e-02, -3.5719e-02,\n",
            "        -2.0983e-02, -2.4309e-02, -3.2900e-02,  1.6533e-02,  3.1891e-03,\n",
            "         1.7845e-02, -9.3074e-03,  7.4291e-03,  3.9633e-02,  2.5780e-02,\n",
            "         3.4890e-03, -2.8969e-02, -1.0231e-02,  2.4490e-02,  4.0221e-02,\n",
            "         3.7594e-02,  3.0401e-02, -3.4872e-02, -2.1837e-02,  4.1196e-02,\n",
            "        -2.5959e-02,  2.0651e-02,  3.9059e-02, -2.9003e-02,  3.7493e-02,\n",
            "        -4.3970e-02, -3.0836e-02, -3.0932e-02,  1.9557e-02,  1.8878e-02,\n",
            "        -4.3263e-03, -2.1990e-02, -2.5845e-02,  3.0024e-05, -3.1667e-02,\n",
            "         7.8716e-03,  1.7578e-02,  3.2362e-02, -3.1484e-02, -4.4306e-03,\n",
            "         6.0720e-04,  2.7843e-02, -1.4041e-02, -9.2546e-03,  7.9556e-03,\n",
            "        -3.6816e-02,  9.9333e-03, -3.8017e-03,  1.4730e-02, -2.5696e-02,\n",
            "         2.2004e-03, -1.0391e-02,  8.3805e-03,  1.9137e-02, -9.9116e-03,\n",
            "        -9.1857e-03,  2.1399e-02, -2.4476e-02,  4.2778e-02,  2.0632e-02,\n",
            "         2.8304e-02, -5.1212e-03,  2.9476e-02, -3.9502e-02, -4.0957e-02,\n",
            "        -7.3787e-04, -3.2187e-02, -6.8666e-03, -3.8305e-02, -1.2079e-02,\n",
            "        -1.3175e-02, -2.8790e-02,  1.2231e-03, -2.8995e-02, -2.2475e-02,\n",
            "         2.5421e-02,  4.4117e-02, -2.8074e-03, -4.0910e-02,  1.4088e-02,\n",
            "         3.2207e-02,  1.2924e-02,  2.2638e-02, -2.6911e-02, -4.3944e-02,\n",
            "         3.5983e-03, -3.3824e-02,  7.3503e-03, -2.3918e-02, -1.9429e-02,\n",
            "         3.7525e-02,  6.1906e-03,  4.4149e-02, -1.7648e-02, -2.7619e-02,\n",
            "        -1.5388e-02, -9.5688e-03,  3.5856e-02, -2.1587e-04, -1.4502e-02,\n",
            "         2.4471e-02, -2.0682e-02,  2.4880e-03,  3.1596e-02,  3.8913e-02,\n",
            "        -3.3630e-02,  3.0122e-03, -6.5533e-03, -3.0982e-02,  3.7437e-03,\n",
            "        -3.2941e-02,  2.7783e-02, -9.7423e-04,  3.8177e-02,  4.1875e-02,\n",
            "        -8.6762e-04,  2.6738e-02, -4.4193e-02, -3.6102e-02,  1.4194e-02,\n",
            "        -6.3487e-03,  1.3989e-02, -3.6956e-04,  1.0554e-02,  3.4670e-02,\n",
            "        -3.8654e-02, -3.6362e-02, -3.8155e-02, -2.3168e-02,  1.3455e-02,\n",
            "         3.1786e-02,  2.6812e-02,  3.7751e-02,  2.7339e-02, -1.4888e-02,\n",
            "        -1.0935e-02, -2.8041e-02], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0241, -0.0149,  0.0365,  ..., -0.0054, -0.0310, -0.0350],\n",
            "        [-0.0120, -0.0133, -0.0136,  ..., -0.0037,  0.0092,  0.0307],\n",
            "        [ 0.0126, -0.0279, -0.0078,  ...,  0.0004,  0.0048, -0.0364],\n",
            "        ...,\n",
            "        [-0.0129, -0.0128, -0.0009,  ..., -0.0170, -0.0279, -0.0384],\n",
            "        [-0.0250,  0.0368, -0.0077,  ...,  0.0195,  0.0250, -0.0036],\n",
            "        [-0.0196,  0.0144, -0.0165,  ...,  0.0079,  0.0233, -0.0209]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0343, -0.0302,  0.0285, -0.0258,  0.0009, -0.0392, -0.0207, -0.0128,\n",
            "        -0.0311, -0.0228,  0.0084], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for item in model.parameters():\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt5yo0fcYb6g",
        "outputId": "7938c184-ed8a-4dea-ef65-4ed3482faa68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16272097.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 325146.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5482351.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 15163115.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data=datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "test_data=datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-rCPSC70Yb6g"
      },
      "outputs": [],
      "source": [
        "#train_data=DataLoader(training_data,shuffle=True)\n",
        "test_data=DataLoader(test_data,batch_size=64,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wSyQ5couYb6h"
      },
      "outputs": [],
      "source": [
        "v_size=0.1\n",
        "data_size=len(training_data)\n",
        "val_size=int(v_size*data_size)\n",
        "train_size=data_size-val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zb_9toGiYb6h"
      },
      "outputs": [],
      "source": [
        "train_dataset,validation_dataset=random_split(training_data,[train_size,val_size])\n",
        "train_data=DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
        "val_data=DataLoader(validation_dataset,batch_size=64,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2kFQo_1sYb6h"
      },
      "outputs": [],
      "source": [
        "learning_rate=0.01\n",
        "Num_epochs=10\n",
        "batch_size=64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QZK9tVCwYb6i"
      },
      "outputs": [],
      "source": [
        "loss=nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GEmNbzTqYb6i"
      },
      "outputs": [],
      "source": [
        "optimizer=optim.SGD(model.parameters(),lr=learning_rate,momentum=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i23S9RfXYb6i"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader,model,loss_fn,optimizer):\n",
        "    size=len(dataloader.dataset)\n",
        "    model.train()# setting the model to training mode\n",
        "    for batch, (X,y) in enumerate(dataloader):\n",
        "        pred=model(X)# computing the prediction and loss\n",
        "        loss=loss_fn(pred,y)\n",
        "        loss.backward()#performing backward propagataion\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if batch%100==0:\n",
        "            loss,current=loss.item(),(batch+1)*len(X)\n",
        "            print(f\"Loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "def test_loop(dataloader,model,loss_fn):\n",
        "    model.eval()#setting the model to evaluation mode\n",
        "    size=len(dataloader.dataset)\n",
        "    num_batches=len(dataloader)\n",
        "    test_loss,correct=0,0\n",
        "    with torch.no_grad():# to not calculate the gradients during test mode\n",
        "        for X,y in dataloader:\n",
        "            pred=model(X)\n",
        "            test_loss+=loss_fn(pred,y).item()\n",
        "            correct+=(pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "        test_loss/=num_batches\n",
        "        correct/=size\n",
        "        print(f\"validation error: \\n validation loss: {test_loss:>8f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvVB7DBkYb6i",
        "outputId": "bec526cb-1bc3-4489-afcb-2b8928eb768a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------------------\n",
            "Loss: 2.399151 [   64/54000]\n",
            "Loss: 1.469479 [ 6464/54000]\n",
            "Loss: 0.844912 [12864/54000]\n",
            "Loss: 0.750746 [19264/54000]\n",
            "Loss: 0.826063 [25664/54000]\n",
            "Loss: 0.593747 [32064/54000]\n",
            "Loss: 0.588964 [38464/54000]\n",
            "Loss: 0.532621 [44864/54000]\n",
            "Loss: 0.570629 [51264/54000]\n",
            "validation error: \n",
            " validation loss: 0.574982\n",
            "\n",
            "Epoch 2\n",
            "-------------------------------------------\n",
            "Loss: 0.562986 [   64/54000]\n",
            "Loss: 0.491878 [ 6464/54000]\n",
            "Loss: 0.479692 [12864/54000]\n",
            "Loss: 0.693917 [19264/54000]\n",
            "Loss: 0.582616 [25664/54000]\n",
            "Loss: 0.472765 [32064/54000]\n",
            "Loss: 0.553427 [38464/54000]\n",
            "Loss: 0.466170 [44864/54000]\n",
            "Loss: 0.602266 [51264/54000]\n",
            "validation error: \n",
            " validation loss: 0.498317\n",
            "\n",
            "Epoch 3\n",
            "-------------------------------------------\n",
            "Loss: 0.528200 [   64/54000]\n",
            "Loss: 0.501709 [ 6464/54000]\n",
            "Loss: 0.576221 [12864/54000]\n",
            "Loss: 0.398370 [19264/54000]\n",
            "Loss: 0.413708 [25664/54000]\n",
            "Loss: 0.370650 [32064/54000]\n",
            "Loss: 0.528302 [38464/54000]\n",
            "Loss: 0.350575 [44864/54000]\n",
            "Loss: 0.519915 [51264/54000]\n",
            "validation error: \n",
            " validation loss: 0.457049\n",
            "\n",
            "Epoch 4\n",
            "-------------------------------------------\n",
            "Loss: 0.593534 [   64/54000]\n",
            "Loss: 0.725259 [ 6464/54000]\n",
            "Loss: 0.489089 [12864/54000]\n",
            "Loss: 0.345937 [19264/54000]\n",
            "Loss: 0.423686 [25664/54000]\n",
            "Loss: 0.356097 [32064/54000]\n",
            "Loss: 0.399647 [38464/54000]\n",
            "Loss: 0.355169 [44864/54000]\n",
            "Loss: 0.426341 [51264/54000]\n",
            "validation error: \n",
            " validation loss: 0.435177\n",
            "\n",
            "Epoch 5\n",
            "-------------------------------------------\n",
            "Loss: 0.651096 [   64/54000]\n",
            "Loss: 0.295600 [ 6464/54000]\n",
            "Loss: 0.346661 [12864/54000]\n",
            "Loss: 0.179315 [19264/54000]\n",
            "Loss: 0.545652 [25664/54000]\n",
            "Loss: 0.463012 [32064/54000]\n",
            "Loss: 0.360414 [38464/54000]\n",
            "Loss: 0.367615 [44864/54000]\n",
            "Loss: 0.427405 [51264/54000]\n",
            "validation error: \n",
            " validation loss: 0.414873\n",
            "\n",
            "Epoch 6\n",
            "-------------------------------------------\n",
            "Loss: 0.395121 [   64/54000]\n",
            "Loss: 0.527805 [ 6464/54000]\n",
            "Loss: 0.347342 [12864/54000]\n",
            "Loss: 0.232511 [19264/54000]\n",
            "Loss: 0.440798 [25664/54000]\n",
            "Loss: 0.304363 [32064/54000]\n",
            "Loss: 0.447650 [38464/54000]\n",
            "Loss: 0.339712 [44864/54000]\n",
            "Loss: 0.353343 [51264/54000]\n",
            "validation error: \n",
            " validation loss: 0.410331\n",
            "\n",
            "Epoch 7\n",
            "-------------------------------------------\n",
            "Loss: 0.285199 [   64/54000]\n",
            "Loss: 0.468816 [ 6464/54000]\n",
            "Loss: 0.329796 [12864/54000]\n",
            "Loss: 0.355918 [19264/54000]\n",
            "Loss: 0.249074 [25664/54000]\n",
            "Loss: 0.381113 [32064/54000]\n",
            "Loss: 0.414806 [38464/54000]\n",
            "Loss: 0.467146 [44864/54000]\n",
            "Loss: 0.393034 [51264/54000]\n",
            "validation error: \n",
            " validation loss: 0.406466\n",
            "\n",
            "Epoch 8\n",
            "-------------------------------------------\n",
            "Loss: 0.367736 [   64/54000]\n",
            "Loss: 0.376019 [ 6464/54000]\n",
            "Loss: 0.208562 [12864/54000]\n",
            "Loss: 0.362240 [19264/54000]\n",
            "Loss: 0.336697 [25664/54000]\n",
            "Loss: 0.264398 [32064/54000]\n",
            "Loss: 0.383122 [38464/54000]\n",
            "Loss: 0.423245 [44864/54000]\n",
            "Loss: 0.317273 [51264/54000]\n",
            "validation error: \n",
            " validation loss: 0.377706\n",
            "\n",
            "Epoch 9\n",
            "-------------------------------------------\n",
            "Loss: 0.525606 [   64/54000]\n",
            "Loss: 0.337935 [ 6464/54000]\n",
            "Loss: 0.376557 [12864/54000]\n",
            "Loss: 0.280286 [19264/54000]\n",
            "Loss: 0.254832 [25664/54000]\n",
            "Loss: 0.403716 [32064/54000]\n",
            "Loss: 0.261757 [38464/54000]\n",
            "Loss: 0.283348 [44864/54000]\n",
            "Loss: 0.269749 [51264/54000]\n",
            "validation error: \n",
            " validation loss: 0.369501\n",
            "\n",
            "Epoch 10\n",
            "-------------------------------------------\n",
            "Loss: 0.343355 [   64/54000]\n",
            "Loss: 0.498496 [ 6464/54000]\n",
            "Loss: 0.182187 [12864/54000]\n",
            "Loss: 0.354152 [19264/54000]\n",
            "Loss: 0.258251 [25664/54000]\n",
            "Loss: 0.322290 [32064/54000]\n",
            "Loss: 0.362490 [38464/54000]\n",
            "Loss: 0.344441 [44864/54000]\n",
            "Loss: 0.418988 [51264/54000]\n",
            "validation error: \n",
            " validation loss: 0.376449\n",
            "\n",
            "Done!!!!!!!\n"
          ]
        }
      ],
      "source": [
        "for t in range(Num_epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------------------\")\n",
        "    train_loop(train_data,model,loss,optimizer)\n",
        "    test_loop(val_data,model,loss)\n",
        "print(\"Done!!!!!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zEwuvR3IYb6j"
      },
      "outputs": [],
      "source": [
        "torch.save(model,'model.pth')\n",
        "model=torch.load('model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qw2WHTWFYb6j"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz2xb-KlYb6j"
      },
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_data))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYRQErKjYb6k",
        "outputId": "df12d29b-3c66-4949-e0a1-5e8bc5f03059"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=11, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "McbtaPvlYb6k"
      },
      "outputs": [],
      "source": [
        "labels_map=[\n",
        "    \"T-Shirt\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle Boot\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MYQFJNiXYb6k"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "for batch in test_data:\n",
        "    inputs, _ = batch  # Assuming the DataLoader returns inputs and labels, but we're only interested in inputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)  # Forward pass to get predictions\n",
        "    probabilities = F.softmax(outputs, dim=1)\n",
        "    _, predicted_classes = torch.max(probabilities, 1)\n",
        "    predictions.extend(predicted_classes.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "ezYXBVJsYb6l",
        "outputId": "b433d96e-ae46-4553-edae-7d0545193886"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for batch_idx, (inputs, labels) in enumerate(test_data):\n",
        "    if batch_idx >= 2:\n",
        "        break  # Only process the first two batches\n",
        "\n",
        "    # Forward pass to get predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "    probabilities = F.softmax(outputs, dim=1)\n",
        "    _, predicted_classes = torch.max(probabilities, 1)\n",
        "\n",
        "    # Convert the predicted class index to class label\n",
        "    predicted_label = labels_map[predicted_classes[0].item()]\n",
        "\n",
        "    # Display the image and its corresponding predicted label\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(inputs[0].permute(1, 2, 0))\n",
        "    plt.title(f'Predicted Label: {predicted_label}')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
